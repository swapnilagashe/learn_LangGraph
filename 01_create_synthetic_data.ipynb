{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import random\n",
    "from langchain_openai.chat_models import AzureChatOpenAI\n",
    "from langchain_core.messages import AIMessage, BaseMessage, HumanMessage,SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_experimental.synthetic_data import create_data_generation_chain\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "s3r = boto3.client('s3', \n",
    "                   aws_access_key_id=os.environ[\"DEV_ACCESS_KEY\"], \n",
    "                   aws_secret_access_key=os.environ[\"DEV_SECRET_ACCESS_KEY\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download test data from dev s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"df_test_v1.xlsx\"\n",
    "fullname = f'swapnil/form_selection_core/excel/' + name\n",
    "s3r.download_file(Bucket = \"datainsights-shared-coupadev-com\", Key = fullname, Filename = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance</th>\n",
       "      <th>easy_form_widget_response_id</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>easy_form_id</th>\n",
       "      <th>easy_form_widget_id</th>\n",
       "      <th>easy_form_response_id</th>\n",
       "      <th>user_submitted_description</th>\n",
       "      <th>easy_form_widget_response_type</th>\n",
       "      <th>backing_attribute</th>\n",
       "      <th>field_name</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_type</th>\n",
       "      <th>status</th>\n",
       "      <th>easy_form_name</th>\n",
       "      <th>easy_form_model</th>\n",
       "      <th>easy_form_status</th>\n",
       "      <th>easy_form_description</th>\n",
       "      <th>form_type</th>\n",
       "      <th>requistion_line_id</th>\n",
       "      <th>header_id</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cbre</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-01 11:09:43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Warning Trip Hazard\" Sign 210mm x 148mm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>freeform</td>\n",
       "      <td>5889876.0</td>\n",
       "      <td>3013667.0</td>\n",
       "      <td>freeform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>monash</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-11 00:20:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEBDEN DAYPLANNER refil</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>freeform</td>\n",
       "      <td>1091278.0</td>\n",
       "      <td>479534.0</td>\n",
       "      <td>freeform</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  instance  easy_form_widget_response_id          updated_at  easy_form_id  \\\n",
       "0     cbre                           NaN 2023-11-01 11:09:43           NaN   \n",
       "1   monash                           NaN 2023-09-11 00:20:35           NaN   \n",
       "\n",
       "   easy_form_widget_id  easy_form_response_id  \\\n",
       "0                  NaN                    NaN   \n",
       "1                  NaN                    NaN   \n",
       "\n",
       "                 user_submitted_description easy_form_widget_response_type  \\\n",
       "0  \"Warning Trip Hazard\" Sign 210mm x 148mm                            NaN   \n",
       "1                   DEBDEN DAYPLANNER refil                            NaN   \n",
       "\n",
       "  backing_attribute field_name  ... subject_type status  easy_form_name  \\\n",
       "0               NaN        NaN  ...          NaN    NaN             NaN   \n",
       "1               NaN        NaN  ...          NaN    NaN             NaN   \n",
       "\n",
       "  easy_form_model easy_form_status easy_form_description form_type  \\\n",
       "0             NaN              NaN                   NaN  freeform   \n",
       "1             NaN              NaN                   NaN  freeform   \n",
       "\n",
       "  requistion_line_id  header_id   channel  \n",
       "0          5889876.0  3013667.0  freeform  \n",
       "1          1091278.0   479534.0  freeform  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path = \"df_test_v1.xlsx\"\n",
    "test_data = pd.read_excel(test_data_path)\n",
    "test_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_llm(**kwargs):\n",
    "    # initialize llm\n",
    "    llm = AzureChatOpenAI(\n",
    "        deployment_name=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "        **kwargs\n",
    "    )\n",
    "    return llm\n",
    "\n",
    "llm= initialize_llm(temperature = 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_personas = ['verbose','concise','step-by-step','casual','formal','spelling-mistake']\n",
    "personas_attributes = {\n",
    "    'verbose':\n",
    "        'writes longer complete sentences that are friendlier and generally include punctuation.',\n",
    "    'concise':\n",
    "        'writes direct queries with minimal non-essential text. You usually omit capitalization and filler phrases',\n",
    "    'step-by-step':\n",
    "        'summarizes the goal of each step before explaining the detailed instructions.',\n",
    "    'casual':\n",
    "        'uses informal language that may not directly reference all the details',\n",
    "    'formal':\n",
    "        'likes to provide detailed information and formal language.',\n",
    "    'spelling-mistake':\n",
    "        'often makes spelling mistakes'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbose = writes longer complete sentences that are friendlier and generally include punctuation.\n",
      " concise = writes direct queries with minimal non-essential text. You usually omit capitalization and filler phrases\n",
      " step-by-step = summarizes the goal of each step before explaining the detailed instructions.\n",
      " casual = uses informal language that may not directly reference all the details\n",
      " formal = likes to provide detailed information and formal language.\n",
      " spelling-mistake = often makes spelling mistakes\n"
     ]
    }
   ],
   "source": [
    "personas_attributes_string = \"\"\n",
    "for key, value in personas_attributes.items():\n",
    "    personas_attributes_string += \"{} = {}\\n \".format(key, value)\n",
    "\n",
    "# To remove the last comma and space\n",
    "personas_attributes_string = personas_attributes_string[:-2]\n",
    "\n",
    "print(personas_attributes_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"\"\"You are an employee in a corporate business and you have the responsibility to purchase or procure goods or services for your organization.\n",
    "You will be provided with a description of the item or service you need to request.\n",
    "Your task is to present this request to an AI Assistant.\n",
    "Use any crucial information such as quantity, amount, business justification, etc., from the provided fields to create a succinct one-line request.\n",
    "Keep your request short and simple. Use the given description wisely and incorporate only the significant details.\n",
    "You may add more information if necessary. If there are any extra preferences provided, utilize them while framing your sentence.\n",
    "Instructions:\n",
    "-You are a user whose persona aligns with the given persona description. Behave accordingly.\n",
    "Item or Service Description: {description}\n",
    "Persona Description: {persona_description}\n",
    "Request:\"\"\")\n",
    "\n",
    "generate = create_data_generation_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard',\n",
       " 'spelling-mistake',\n",
       " 'often makes spelling mistakes')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_description =test_data['user_submitted_description'][10].replace('\"','')\n",
    "persona = random.choice(all_personas)\n",
    "persona_description = personas_attributes[persona]\n",
    "item_description, persona,persona_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard', 'persona_description': 'often makes spelling mistakes', 'text': 'Please procure a Vanguard House service to remove damaged traffic signs and replace them with new ones, including a 168mm bolt bollard.'}"
     ]
    }
   ],
   "source": [
    "for chunk in generate.stream({\n",
    "                \"description\": item_description,\n",
    "                \"persona_description\":persona_description,\n",
    "            }):\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard',\n",
       " 'persona_description': 'often makes spelling mistakes',\n",
       " 'text': 'Hi AI Assistant, please procure a Vanguard House to remove damaged traffic signs and replace them with new ones, including a 168mm bolt bollard. Thank you!'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate.invoke({\n",
    "                \"description\": item_description,\n",
    "                \"persona_description\":persona_description,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard',\n",
       " 'persona_description': 'often makes spelling mistakes',\n",
       " 'text': 'Dear AI Assistant, please assist in procuring a Vanguard House service to replace damaged traffic signs and install new ones, including a 168mm bolt bollard. Thank you.'}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_reflection = initialize_llm(temperature=1e-9 , streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_template=\"\"\"You are proficient in analyzing, critiquing, and recommending enhancements to the training data used for educating a chatbot on procurement requests.\n",
    "The chatbot should be capable of generalizing an array of user inquiries. It's assumed that the chatbot will only cater to users with the following attributes.\n",
    "{personas_attributes_string}\n",
    "Below are the specifics regarding the generated query along with the original description utilized to generate the query:\n",
    "Original Item or Service Description: {description}\n",
    "Persona Description (Individual making the request): {persona_description}\n",
    "Generated Query: {text}.\n",
    "\n",
    "Your task is to analyse and report whether the 'Generated Query' follows the exact attributes of the Persona Description\n",
    "\\n{format_instructions}\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personas_attributes_string': 'verbose = writes longer complete sentences that are friendlier and generally include punctuation.\\n concise = writes direct queries with minimal non-essential text. You usually omit capitalization and filler phrases\\n step-by-step = summarizes the goal of each step before explaining the detailed instructions.\\n casual = uses informal language that may not directly reference all the details\\n formal = likes to provide detailed information and formal language.\\n spelling-mistake = often makes spelling mistakes',\n",
       " 'description': 'Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard',\n",
       " 'persona_description': 'often makes spelling mistakes',\n",
       " 'text': 'Dear AI Assistant, please assist in procuring a Vanguard House service to replace damaged traffic signs and install new ones, including a 168mm bolt bollard. Thank you.'}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_reflection={}\n",
    "input_reflection['personas_attributes_string']=personas_attributes_string\n",
    "input_reflection['description']=chunk['description']\n",
    "input_reflection['persona_description']=chunk['persona_description']\n",
    "input_reflection['text']=chunk['text']\n",
    "input_reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"observation\": {\"title\": \"Observation\", \"description\": \"Suggestion to improve the generated query take to make the query accurately follow persona atributes\", \"type\": \"string\"}, \"reason_for_observation\": {\"title\": \"Reason For Observation\", \"description\": \"detailed reason for the specific observation\", \"type\": \"string\"}, \"action\": {\"title\": \"Action\", \"description\": \"action to take based on observation\", \"type\": \"string\"}, \"valid\": {\"title\": \"Valid\", \"description\": \"Whether the generated query for item/service description accurately follows persona atributes\", \"type\": \"boolean\"}}, \"required\": [\"observation\", \"reason_for_observation\", \"action\", \"valid\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "class IsQueryValid(BaseModel):\n",
    "    observation: str = Field(description=\"Suggestion to improve the generated query take to make the query accurately follow persona atributes\")\n",
    "    reason_for_observation:str = Field(description=\"detailed reason for the specific observation\")\n",
    "    action: str = Field(description=\"action to take based on observation\")\n",
    "    valid: bool = Field(description=\"Whether the generated query for item/service description accurately follows persona atributes\")\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "reflection_parser = PydanticOutputParser(pydantic_object=IsQueryValid)\n",
    "\n",
    "print(reflection_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'personas_attributes_string': 'verbose = writes longer complete sentences that are friendlier and generally include punctuation.\\n concise = writes direct queries with minimal non-essential text. You usually omit capitalization and filler phrases\\n step-by-step = summarizes the goal of each step before explaining the detailed instructions.\\n casual = uses informal language that may not directly reference all the details\\n formal = likes to provide detailed information and formal language.\\n spelling-mistake = often makes spelling mistakes',\n",
       " 'description': 'Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard',\n",
       " 'persona_description': 'often makes spelling mistakes',\n",
       " 'text': 'Dear AI Assistant, please assist in procuring a Vanguard House service to replace damaged traffic signs and install new ones, including a 168mm bolt bollard. Thank you.'}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_prompt = PromptTemplate(\n",
    "    template=reflection_template,\n",
    "    input_variables=['personas_attributes_string','description', 'persona_description', 'text'],\n",
    "    partial_variables={\"format_instructions\": reflection_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_chain = reflection_prompt | llm_reflection | reflection_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsQueryValid(observation='The generated query does not accurately follow the persona attributes.', reason_for_observation='The generated query is too formal and does not contain any spelling mistakes, which contradicts the persona description of often making spelling mistakes.', action='Revise the generated query to include spelling mistakes and use more informal language.', valid=False)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflection_result = reflection_chain.invoke(input_reflection)\n",
    "reflection_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages:Annotated[Sequence[BaseMessage],operator.add]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Vanguard House - To remove damaged traffic signs and replace with new including 168mm bolt bollard',\n",
       " 'persona_description': 'often makes spelling mistakes',\n",
       " 'text': 'Please procure a Vanguard House service to remove damaged traffic signs and replace them with new ones, including a 168mm bolt bollard.'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsQueryValid(observation='The generated query does not accurately follow the persona attributes.', reason_for_observation='The generated query is too formal and does not contain any spelling mistakes, which contradicts the persona description of often making spelling mistakes.', action='Revise the generated query to include spelling mistakes and use more informal language.', valid=False)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflection_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_query(state):\n",
    "    messages = state['messages']\n",
    "    args ={}\n",
    "    args['description']=messages['description']\n",
    "    args['persona_description']=messages['persona_description']\n",
    "    args['text']=messages['text']\n",
    "    generated_query = generate.invoke(args)['text']\n",
    "    return {\"messages\":[generated_query]}\n",
    "\n",
    "def reset_state(state):\n",
    "    pass\n",
    "\n",
    "def formatted_reflection_res(reflection_result):\n",
    "    formatted_list_messages =[]\n",
    "    formatted_list_messages.append(f'observation - {reflection_result.observation}')\n",
    "    formatted_list_messages.append(f'reason_for_observation - {reflection_result.reason_for_observation}')\n",
    "    formatted_list_messages.append(f'action - {reflection_result.action}')\n",
    "    formatted_list_messages.append(f'valid - {reflection_result.valid}')\n",
    "    return formatted_list_messages\n",
    "\n",
    "def reflect(state):\n",
    "    messages = state['messages']\n",
    "    \n",
    "    args ={}\n",
    "    args['description']=messages['description']\n",
    "    args['persona_description']=messages['persona_description']\n",
    "    args['text']=messages['text']\n",
    "    reflection_res = reflection_chain.invoke(input_reflection)\n",
    "    formatted_res =formatted_reflection_res(reflection_res)\n",
    "    return {\"messages\":formatted_res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    if \"function_call\" not in last_message.additional_kwargs:\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "\n",
    "def call_model(state):\n",
    "    messages = state['messages']\n",
    "    response =llm_with_tools.invoke(messages)\n",
    "    # we return a list that will get added to the existing list\n",
    "    return {\"messages\":[response]}\n",
    "\n",
    "def call_tool(state):\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    action = ToolInvocation(\n",
    "        tool = last_message.additional_kwargs[\"function_call\"][\"name\"],\n",
    "        tool_input = json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),\n",
    "    )\n",
    "    \n",
    "    response  = tool_executor.invoke(action)\n",
    "    \n",
    "    # use the response to create a function message\n",
    "    function_message = FunctionMessage(content = str(response), name = action.tool)\n",
    "    \n",
    "    # we return a list that will get added to the existing list\n",
    "    return {\"messages\":[function_message]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# create nodes\n",
    "workflow.add_node(\"agent\",call_model)\n",
    "workflow.add_node(\"action\",call_tool)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# add conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\"continue\":\"action\",\n",
    "    \"end\":END\n",
    "    }\n",
    ")\n",
    "\n",
    "# add a normal edge\n",
    "# because we always want to go to the agent after going to the action\n",
    "workflow.add_edge(\"action\",\"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflection_template=\"\"\"You are proficient in analyzing, critiquing, and recommending enhancements to the training data used for educating a chatbot on procurement requests.\n",
    "The chatbot should be capable of generalizing an array of user inquiries. It's assumed that the chatbot will only cater to users with the following attributes.\n",
    "{personas_attributes_string}\n",
    "For instance, if the Persona Description indicates that a user tends to make spelling errors, then at least one spelling mistake should be present in the generated query, otherwise, the query would be deemed invalid.\n",
    "Similarly, if the persona possesses different traits, the generated query should align with those traits.\n",
    "Below are the specifics regarding the generated query along with the original description utilized to generate the query:\n",
    "Original Item or Service Description: {description}\n",
    "Persona Description (Individual making the request): {persona_description}\n",
    "Generated Query: {text}.\n",
    "\\n{format_instructions}\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ret = generate.invoke({\n",
    "                \"description\": item_description,\n",
    "                \"persona\": persona,\n",
    "                \"persona_description\":persona_description,\n",
    "            })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_tree_search",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
